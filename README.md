# ğŸš€ Pipeline de Streaming IoT avec Spark Structured Streaming & Kafka

---

## ğŸ§  Contexte

**SmartTech** est une entreprise spÃ©cialisÃ©e dans les **services connectÃ©s** et les **solutions IoT**. Des capteurs installÃ©s dans des bÃ¢timents intelligents gÃ©nÃ¨rent en continu des donnÃ©es (tempÃ©rature, humiditÃ©, COâ‚‚, etc.).

ğŸ¯ **Objectif du projet** : concevoir et implÃ©menter un **pipeline de streaming temps rÃ©el** capable de :

* ingÃ©rer des donnÃ©es en continu,
* les transformer et nettoyer,
* les stocker de maniÃ¨re fiable pour lâ€™analyse.

ğŸ§° **Stack technique (onâ€‘premise)** :

* ğŸŸ  **Apache Kafka** â€” message broker
* ğŸ”µ **Apache Spark Structured Streaming** â€” moteur de traitement temps rÃ©el
* ğŸŸ¢ **Delta Lake** â€” stockage transactionnel

---

## ğŸ—ï¸ Architecture globale

```text
[ Simulateur de capteurs ]
            |
            v
        [ Kafka ]
            |
            v
[ Spark Structured Streaming ]
            |
            v
     [ Delta Lake ]
      (Bronze / Silver)
```

---

## âš™ï¸ PrÃ©requis & Nettoyage (OBLIGATOIRE)

### ğŸ”¹ PrÃ©requis

* Docker Desktop installÃ© et lancÃ©
* Python **3.10+**
* **uv** installÃ©

---

### ğŸ”¹ Installation des dÃ©pendances

Le projet utilise **uv** pour la gestion des dÃ©pendances.

âœ… Si `pyproject.toml` et `uv.lock` sont prÃ©sents :

```bash
uv sync
```

ğŸ” Sinon :

```bash
uv add pyspark delta-spark confluent-kafka
uv sync
```

---

### ğŸ§¹ Nettoyage des sorties (AVANT TOUTE EXÃ‰CUTION)

âš ï¸ **Ã‰tape obligatoire**, notamment lors du clonage.

Les dossiers de checkpoints et de sorties Delta contiennent des **Ã©tats locaux** (offsets Kafka, Ã©tat Spark). Sans nettoyage, le pipeline peut ne pas redÃ©marrer correctement.

ğŸ“ Depuis la racine du projet :

#### ğŸ¥‰ Bronze (Partie 2.1)

```bash
rm -rf data/checkpoints/bronze_checkpoints/*
rm -rf data/output/bronze_output/*
```

#### ğŸ¥ˆ Silver (Partie 2.2)

```bash
rm -rf data/checkpoints/silver_kafka
rm -rf data/output/silver_delta
```

---

## ğŸ¥‰ Partie 2.1 â€” Pipeline simple (JSON â†’ Delta Bronze)

### ğŸ¯ Objectif

DÃ©couvrir **Spark Structured Streaming** via un flux simulÃ© par fichiers, sans message broker.

### ğŸ› ï¸ FonctionnalitÃ©s

* Lecture de fichiers **JSON en streaming**
* Nettoyage et typage des donnÃ©es
* Ã‰criture en **Delta Lake â€” Bronze**
* TolÃ©rance aux pannes via **checkpointing**

### ğŸ“‚ Flux de donnÃ©es

```text
Fichiers JSON â†’ Spark Structured Streaming â†’ Delta Bronze
```

### â–¶ï¸ Lancer la partie Bronze

**Terminal 1** :

```bash
uv run python src/bronze_stream.py
```

**Terminal 2** (simulation du flux) :

```bash
cp data/source_json/*.json data/input/
```

ğŸ’¡ Copier les fichiers progressivement permet dâ€™observer le comportement streaming.

---

## ğŸ¥ˆ Partie 2.2 â€” Pipeline avancÃ© avec Kafka (Kafka â†’ Delta Silver)

### ğŸ¯ Objectif

Mettre en place un **vrai flux temps rÃ©el** grÃ¢ce Ã  Kafka, afin de dÃ©coupler les producteurs et consommateurs et fiabiliser lâ€™architecture.

---

### ğŸ§© RÃ´le de Kafka

Kafka apporte :

* ğŸ”— le **dÃ©couplage** producteurs / consommateurs
* ğŸ“ˆ lâ€™absorption des pics de charge
* ğŸ›¡ï¸ la tolÃ©rance aux pannes
* ğŸ” la **rejouabilitÃ©** via les offsets

ğŸ“Œ Concepts clÃ©s :

* **Topic** : `iot_smartech`
* **Partitions** : parallÃ©lisme
* **Offsets** : position de lecture
* **Consumer groups** : scalabilitÃ©

---

### âš™ï¸ Mise en Å“uvre

#### 1ï¸âƒ£ Lancer Kafka (Docker)

```bash
cd kafka
docker compose up -d
docker compose ps
```

---

#### 2ï¸âƒ£ CrÃ©er le topic Kafka

```bash
docker compose exec kafka kafka-topics \
  --bootstrap-server kafka:29092 \
  --create \
  --topic iot_smartech \
  --partitions 3 \
  --replication-factor 1
```

VÃ©rification :

```bash
docker compose exec kafka kafka-topics \
  --bootstrap-server kafka:29092 --list
```

---

#### 3ï¸âƒ£ Consumer Spark (Kafka â†’ Silver)

**Terminal 1** :

```bash
uv run python src/silver_from_kafka.py
```

â³ Le job reste actif : comportement normal en streaming.

---

#### 4ï¸âƒ£ Producer IoT (simulateur de capteurs)

**Terminal 2** :

```bash
uv run python src/producer_iot.py
```

Les Ã©vÃ©nements IoT sont envoyÃ©s en continu dans Kafka.

---

## ğŸ§± Architecture MÃ©daillon

| Niveau    | RÃ´le                                      |
| --------- | ----------------------------------------- |
| ğŸ¥‰ Bronze | DonnÃ©es brutes / quasi brutes             |
| ğŸ¥ˆ Silver | DonnÃ©es nettoyÃ©es et normalisÃ©es          |
| ğŸ¥‡ Gold   | DonnÃ©es mÃ©tiers agrÃ©gÃ©es (non implÃ©mentÃ©) |

---

## ğŸ§ª VÃ©rifications

* Le topic `iot_smartech` est visible dans Kafka
* Les offsets augmentent cÃ´tÃ© consumer
* Le dossier `data/output/silver_delta` contient :

  * `_delta_log/`
  * des fichiers `part-*.parquet`

---

## ğŸ›‘ ArrÃªt du pipeline

* Stopper le producer : `Ctrl + C`
* Stopper le consumer Spark : `Ctrl + C`
* ArrÃªter Kafka :

```bash
docker compose down
```

---

## ğŸ§  Conclusion

Ce projet met en Å“uvre une **architecture de streaming temps rÃ©el complÃ¨te**, proche des standards industriels. Il dÃ©montre :

* lâ€™intÃ©rÃªt de **Kafka** pour le dÃ©couplage et la fiabilitÃ©,
* la puissance de **Spark Structured Streaming** pour le traitement continu,
* lâ€™apport de **Delta Lake** pour un stockage transactionnel.

Le pipeline est **scalable, tolÃ©rant aux pannes et rejouable**, constituant une base solide pour des usages avancÃ©s (dashboards temps rÃ©el, alerting, machine learning).

*Projet rÃ©alisÃ© par Lucas Hzl*